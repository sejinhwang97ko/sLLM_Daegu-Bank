{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b152fb-bcb6-40c7-8c93-32c90a55218e",
   "metadata": {},
   "source": [
    "이 실습은 Runpod에서 A100 SXM GPU 1개로 진행되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2591659b-83e1-45d7-b166-2c85a2f74367",
   "metadata": {},
   "source": [
    "## 1. 필요한 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e226b522-6b01-489a-a845-d840429de4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.14.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.8.61)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.45.1 in /usr/local/lib/python3.11/dist-packages (4.45.1)\n",
      "Requirement already satisfied: datasets==3.0.1 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
      "Requirement already satisfied: accelerate==0.34.2 in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
      "Requirement already satisfied: trl==0.11.1 in /usr/local/lib/python3.11/dist-packages (0.11.1)\n",
      "Requirement already satisfied: peft==0.13.0 in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (2025.7.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.1) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.1) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.1) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.1) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.1) (3.12.15)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.34.2) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.34.2) (2.4.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.11/dist-packages (from trl==0.11.1) (0.9.27)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.1) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.1) (1.1.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==3.0.1) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.1) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.1) (2025.1.31)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.34.2) (12.8.61)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.11.1) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.11.1) (14.1.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.11.1) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.11.1) (4.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.34.2) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.0.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.0.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.0.1) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.0.1) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate==0.34.2) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"torch==2.4.0\"\n",
    "%pip install \"transformers==4.45.1\" \"datasets==3.0.1\" \"accelerate==0.34.2\" \"trl==0.11.1\" \"peft==0.13.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecde1164-6314-4051-b163-e4dd0697c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.11/dist-packages (2.2.0+cu121)\n",
      "Requirement already satisfied: torchvision==0.17.0+cu121 in /usr/local/lib/python3.11/dist-packages (0.17.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (4.14.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.0+cu121) (2.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.0+cu121) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.0+cu121) (11.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.8.61)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0+cu121) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0+cu121) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0+cu121) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0+cu121) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.2.0 torchvision==0.17.0+cu121 --extra-index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763a326a-e01f-4f2f-bc1b-720d2cdb0b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: 2: No such file or directory\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e75c03-fc10-4320-b13e-c4d63989e0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91394a-4b7e-415f-8a41-0ee783d41dc3",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44fc9e67-2865-46c8-9d5d-99b5a227a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef323ce1-aeb4-446d-a331-6468e83d42c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 크기: 1000\n",
      "\n",
      "전체 데이터 분할 결과: Train 800개, Test 200개\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 1. 허깅페이스 허브에서 데이터셋 로드\n",
    "dataset = load_dataset(\"julietz/law_term_2\", split=\"train\")\n",
    "\n",
    "# 2. 전체 데이터 크기만 출력\n",
    "print(\"전체 데이터 크기:\", len(dataset))\n",
    "\n",
    "# 3. train/test 분할 비율 설정\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# 4. 전체 데이터의 인덱스를 train/test로 분할\n",
    "data_indices = list(range(len(dataset)))\n",
    "test_size = int(len(data_indices) * test_ratio)\n",
    "\n",
    "test_data = data_indices[:test_size]\n",
    "train_data = data_indices[test_size:]\n",
    "\n",
    "# 5. OpenAI format으로 데이터 변환을 위한 함수\n",
    "def format_data(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": sample[\"system_prompt\"],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": sample[\"user_prompt\"],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": str(sample[\"assistant\"])\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "# 6. 분할된 데이터를 OpenAI format으로 변환\n",
    "train_dataset = [format_data(dataset[i]) for i in train_data]\n",
    "test_dataset = [format_data(dataset[i]) for i in test_data]\n",
    "\n",
    "# 7. 최종 데이터셋 크기 출력\n",
    "print(f\"\\n전체 데이터 분할 결과: Train {len(train_dataset)}개, Test {len(test_dataset)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4390cd7e-a31c-414a-97d2-a4bd3cc83a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '당신은 법령 상담을 위한 챗봇 데이터를 생성하는 데이터 전문가입니다.\\n\\n당신의 역할은 아래 두 가지 작업을 수행하는 것입니다:\\n\\n1. 주어진 \"법령 용어(법령정의사전)\"를 기반으로, 고객이 자연스럽게 질문할 법한 문장을 생성하세요.\\n2. 주어진 \"법령 용어\"의 \"사전식 풀이\"를 바탕으로, 고객에게 친절하고 정확하게 설명하는 답변을 작성하세요.\\n\\n---\\n\\n[1] 질문 문장 생성 규칙:\\n- 말투는 자연스럽고 일상적인 질문 형태로 작성할 것\\n- 문장은 짧고 간결하게, 대략적인 수준으로 작성할 것\\n- 다음과 같은 표현을 활용할 것: \"뭐예요?\", \"뭔가요?\", \"설명해 주세요.\"\\n- 용어만 나열하지 말고, 반드시 문장 형태로 만들 것\\n- 사람을 지칭하는 경우에는 \"누구인가요?\", \"누구를 말하는 건가요?\"처럼 질문할 것\\n- 반드시 질문 문장만 출력하고, 다른 설명이나 안내 문구는 출력하지 말 것\\n\\n예시:\\n- 입력: 1인당 GNI → 출력: 1인당 GNI가 뭔가요?\\n- 입력: 1종 금융투자업자 → 출력: 1종 금융투자업자는 누구를 말하는 건가요?\\n\\n---\\n\\n[2] 정의 설명 및 출처 처리 규칙:\\n- 두 번째 작업의 결과는 반드시 파이썬의 dictionary 형식으로 출력해야 합니다.\\n- 큰따옴표(\") 안에 작은따옴표(\\')나 다른 따옴표를 넣지 마세요. JSON 파싱 오류가 발생합니다.\\n- 해당 항목이 없을 경우에는 \"없음\"이라는 표현 대신, 빈 문자열(\"\") 또는 빈 리스트([])를 사용해야 합니다.\\n\\n요구 조건:\\n- 딱딱하거나 기계적인 문장은 피하고, 자연스럽고 격식 있는 설명을 작성하세요.\\n- 어려운 정의는 2~3문장으로 풀어 설명해 주세요. 단, 중복된 표현은 삼가세요.\\n- 정의 설명 결과는 \"법령용어정의\"라는 키에 담아야 합니다.\\n\\n출처 관련 규칙:\\n- 출처가 없을 경우:\\n  {\"법령용어정의\": \"...\", \"출처유무\": false}\\n\\n- 출처가 있을 경우:\\n  {\"법령용어정의\": \"...\", \"출처유무\": true, \"출처\": [각 출처 문자열에서 대괄호([) 앞까지 잘라낸 법령명 리스트]}\\n\\n예시 입력 및 출력:\\n- 입력: {\\'LsTrmService\\': {\\'법령용어일련번호\\': [\\'5077141\\', \\'2430005\\'], \\'법령용어명_한글\\': [\\'4교대근무\\', \\'4교대근무\\'], \\'법령용어명_한자\\': [\\'4교대근무\\', \\'4교대근무\\'], \\'법령용어코드\\': [\\'011402\\', \\'011402\\'], \\'법령용어코드명\\': [\\'법령정의사전\\', \\'법령정의사전\\'], \\'출처\\': [\\'기상청 청원경찰 복무 및 징계규정[기상청훈령 제1117호, 2024.5.1., 일부개정]\\', \\'환경부 전일근무관서 교대근무에 관한 규정[환경부훈령 제1144호, 2015.2.27., 제정]\\'], \\'법령용어정의\\': [\\'주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말한다.\\', \\'교대근무자가 주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라  4일 또는 8일을 주기로 하여 실시하는 것을 말한다.\\']}}\\n- 출력: \\n{\"법령용어정의\": \"주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말합니다.\"\\n\"출처유무\": true,\\n\"출처\": [\"기상청 청원경찰 복무 및 징계규정\", \"환경부 전일근무관서 교대근무에 관한 규정\"]}\\n\\n'},\n",
       " {'role': 'user', 'content': 'complement가 뭐예요?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '{\\'법령용어정의\\': \"complement는 \\'보완\\'을 의미합니다. 이는 어떤 것을 완전하게 만들기 위해 추가하거나 개선하는 것을 뜻합니다. 예를 들어, 부족한 부분을 채워서 전체를 더 완벽하게 만드는 것을 말합니다.\", \\'출처\\': None, \\'출처유무\\': False}'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 345번 데이터 출력\n",
    "train_dataset[345][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afc8f819-89cc-445a-999d-a6299a08d7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "# 리스트 형태에서 다시 Dataset 객체로 변경\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))\n",
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "test_dataset = Dataset.from_list(test_dataset)\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1769a733-1ac3-411c-9fcd-0220aedd042a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': '당신은 법령 상담을 위한 챗봇 데이터를 생성하는 데이터 전문가입니다.\\n\\n당신의 역할은 아래 두 가지 작업을 수행하는 것입니다:\\n\\n1. 주어진 \"법령 용어(법령정의사전)\"를 기반으로, 고객이 자연스럽게 질문할 법한 문장을 생성하세요.\\n2. 주어진 \"법령 용어\"의 \"사전식 풀이\"를 바탕으로, 고객에게 친절하고 정확하게 설명하는 답변을 작성하세요.\\n\\n---\\n\\n[1] 질문 문장 생성 규칙:\\n- 말투는 자연스럽고 일상적인 질문 형태로 작성할 것\\n- 문장은 짧고 간결하게, 대략적인 수준으로 작성할 것\\n- 다음과 같은 표현을 활용할 것: \"뭐예요?\", \"뭔가요?\", \"설명해 주세요.\"\\n- 용어만 나열하지 말고, 반드시 문장 형태로 만들 것\\n- 사람을 지칭하는 경우에는 \"누구인가요?\", \"누구를 말하는 건가요?\"처럼 질문할 것\\n- 반드시 질문 문장만 출력하고, 다른 설명이나 안내 문구는 출력하지 말 것\\n\\n예시:\\n- 입력: 1인당 GNI → 출력: 1인당 GNI가 뭔가요?\\n- 입력: 1종 금융투자업자 → 출력: 1종 금융투자업자는 누구를 말하는 건가요?\\n\\n---\\n\\n[2] 정의 설명 및 출처 처리 규칙:\\n- 두 번째 작업의 결과는 반드시 파이썬의 dictionary 형식으로 출력해야 합니다.\\n- 큰따옴표(\") 안에 작은따옴표(\\')나 다른 따옴표를 넣지 마세요. JSON 파싱 오류가 발생합니다.\\n- 해당 항목이 없을 경우에는 \"없음\"이라는 표현 대신, 빈 문자열(\"\") 또는 빈 리스트([])를 사용해야 합니다.\\n\\n요구 조건:\\n- 딱딱하거나 기계적인 문장은 피하고, 자연스럽고 격식 있는 설명을 작성하세요.\\n- 어려운 정의는 2~3문장으로 풀어 설명해 주세요. 단, 중복된 표현은 삼가세요.\\n- 정의 설명 결과는 \"법령용어정의\"라는 키에 담아야 합니다.\\n\\n출처 관련 규칙:\\n- 출처가 없을 경우:\\n  {\"법령용어정의\": \"...\", \"출처유무\": false}\\n\\n- 출처가 있을 경우:\\n  {\"법령용어정의\": \"...\", \"출처유무\": true, \"출처\": [각 출처 문자열에서 대괄호([) 앞까지 잘라낸 법령명 리스트]}\\n\\n예시 입력 및 출력:\\n- 입력: {\\'LsTrmService\\': {\\'법령용어일련번호\\': [\\'5077141\\', \\'2430005\\'], \\'법령용어명_한글\\': [\\'4교대근무\\', \\'4교대근무\\'], \\'법령용어명_한자\\': [\\'4교대근무\\', \\'4교대근무\\'], \\'법령용어코드\\': [\\'011402\\', \\'011402\\'], \\'법령용어코드명\\': [\\'법령정의사전\\', \\'법령정의사전\\'], \\'출처\\': [\\'기상청 청원경찰 복무 및 징계규정[기상청훈령 제1117호, 2024.5.1., 일부개정]\\', \\'환경부 전일근무관서 교대근무에 관한 규정[환경부훈령 제1144호, 2015.2.27., 제정]\\'], \\'법령용어정의\\': [\\'주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말한다.\\', \\'교대근무자가 주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라  4일 또는 8일을 주기로 하여 실시하는 것을 말한다.\\']}}\\n- 출력: \\n{\"법령용어정의\": \"주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말합니다.\"\\n\"출처유무\": true,\\n\"출처\": [\"기상청 청원경찰 복무 및 징계규정\", \"환경부 전일근무관서 교대근무에 관한 규정\"]}\\n\\n',\n",
       "   'role': 'system'},\n",
       "  {'content': 'allotment이 뭐예요?', 'role': 'user'},\n",
       "  {'content': \"{'법령용어정의': 'allotment은 배당, 부담액, 분담, 분담액, 분배, 할당을 의미합니다. 즉, 어떤 자원이나 비용을 여러 부분으로 나누어 할당하는 것을 말합니다. 예를 들어, 회사의 이익을 주주들에게 배당하는 경우나, 프로젝트 비용을 여러 부서에 분담하는 상황에서 사용될 수 있습니다.', '출처': None, '출처유무': False}\",\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5161949a-b3a1-4ebf-8773-ef56f2d2cf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c0b4a39f6944e392521c403b3ea83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset.save_to_disk(\"test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb95f34-2494-4ce8-9161-fdcfa563f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82bf63ca-407f-4b53-ab18-3d422def82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a52be8-3af6-44d8-bf39-5dc14319dc78",
   "metadata": {},
   "source": [
    "## 2. 모델 로드 및 템플릿 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212cd2a7-ac0b-4c8c-8926-c1d5d80f2171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135bc5747ae34398bf2c19c303095302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅페이스 모델 ID\n",
    "model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\" \n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc6e96a3-0d81-4e76-a385-d1c6e8146dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 법령 상담을 위한 챗봇 데이터를 생성하는 데이터 전문가입니다.\n",
      "\n",
      "당신의 역할은 아래 두 가지 작업을 수행하는 것입니다:\n",
      "\n",
      "1. 주어진 \"법령 용어(법령정의사전)\"를 기반으로, 고객이 자연스럽게 질문할 법한 문장을 생성하세요.\n",
      "2. 주어진 \"법령 용어\"의 \"사전식 풀이\"를 바탕으로, 고객에게 친절하고 정확하게 설명하는 답변을 작성하세요.\n",
      "\n",
      "---\n",
      "\n",
      "[1] 질문 문장 생성 규칙:\n",
      "- 말투는 자연스럽고 일상적인 질문 형태로 작성할 것\n",
      "- 문장은 짧고 간결하게, 대략적인 수준으로 작성할 것\n",
      "- 다음과 같은 표현을 활용할 것: \"뭐예요?\", \"뭔가요?\", \"설명해 주세요.\"\n",
      "- 용어만 나열하지 말고, 반드시 문장 형태로 만들 것\n",
      "- 사람을 지칭하는 경우에는 \"누구인가요?\", \"누구를 말하는 건가요?\"처럼 질문할 것\n",
      "- 반드시 질문 문장만 출력하고, 다른 설명이나 안내 문구는 출력하지 말 것\n",
      "\n",
      "예시:\n",
      "- 입력: 1인당 GNI → 출력: 1인당 GNI가 뭔가요?\n",
      "- 입력: 1종 금융투자업자 → 출력: 1종 금융투자업자는 누구를 말하는 건가요?\n",
      "\n",
      "---\n",
      "\n",
      "[2] 정의 설명 및 출처 처리 규칙:\n",
      "- 두 번째 작업의 결과는 반드시 파이썬의 dictionary 형식으로 출력해야 합니다.\n",
      "- 큰따옴표(\") 안에 작은따옴표(')나 다른 따옴표를 넣지 마세요. JSON 파싱 오류가 발생합니다.\n",
      "- 해당 항목이 없을 경우에는 \"없음\"이라는 표현 대신, 빈 문자열(\"\") 또는 빈 리스트([])를 사용해야 합니다.\n",
      "\n",
      "요구 조건:\n",
      "- 딱딱하거나 기계적인 문장은 피하고, 자연스럽고 격식 있는 설명을 작성하세요.\n",
      "- 어려운 정의는 2~3문장으로 풀어 설명해 주세요. 단, 중복된 표현은 삼가세요.\n",
      "- 정의 설명 결과는 \"법령용어정의\"라는 키에 담아야 합니다.\n",
      "\n",
      "출처 관련 규칙:\n",
      "- 출처가 없을 경우:\n",
      "  {\"법령용어정의\": \"...\", \"출처유무\": false}\n",
      "\n",
      "- 출처가 있을 경우:\n",
      "  {\"법령용어정의\": \"...\", \"출처유무\": true, \"출처\": [각 출처 문자열에서 대괄호([) 앞까지 잘라낸 법령명 리스트]}\n",
      "\n",
      "예시 입력 및 출력:\n",
      "- 입력: {'LsTrmService': {'법령용어일련번호': ['5077141', '2430005'], '법령용어명_한글': ['4교대근무', '4교대근무'], '법령용어명_한자': ['4교대근무', '4교대근무'], '법령용어코드': ['011402', '011402'], '법령용어코드명': ['법령정의사전', '법령정의사전'], '출처': ['기상청 청원경찰 복무 및 징계규정[기상청훈령 제1117호, 2024.5.1., 일부개정]', '환경부 전일근무관서 교대근무에 관한 규정[환경부훈령 제1144호, 2015.2.27., 제정]'], '법령용어정의': ['주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말한다.', '교대근무자가 주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라  4일 또는 8일을 주기로 하여 실시하는 것을 말한다.']}}\n",
      "- 출력: \n",
      "{\"법령용어정의\": \"주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말합니다.\"\n",
      "\"출처유무\": true,\n",
      "\"출처\": [\"기상청 청원경찰 복무 및 징계규정\", \"환경부 전일근무관서 교대근무에 관한 규정\"]}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "allotment이 뭐예요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{'법령용어정의': 'allotment은 배당, 부담액, 분담, 분담액, 분배, 할당을 의미합니다. 즉, 어떤 자원이나 비용을 여러 부분으로 나누어 할당하는 것을 말합니다. 예를 들어, 회사의 이익을 주주들에게 배당하는 경우나, 프로젝트 비용을 여러 부서에 분담하는 상황에서 사용될 수 있습니다.', '출처': None, '출처유무': False}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 적용\n",
    "text = tokenizer.apply_chat_template(\n",
    "    train_dataset[0][\"messages\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801263cf-ac85-4e26-9fc6-dbd057552905",
   "metadata": {},
   "source": [
    "## 3. LoRA와 SFTConfig 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2266ebe9-d3ce-4fed-956b-6a830acfe0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        r=8,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ae4257-f495-4a5a-a7e6-852455deb61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir=\"llama3-8b-qa-ko\",           # 저장될 디렉토리와 저장소 ID\n",
    "    num_train_epochs=3,                      # 학습할 총 에포크 수 \n",
    "    per_device_train_batch_size=2,           # GPU당 배치 크기\n",
    "    gradient_accumulation_steps=2,           # 그래디언트 누적 스텝 수\n",
    "    gradient_checkpointing=True,             # 메모리 절약을 위한 체크포인팅\n",
    "    optim=\"adamw_torch_fused\",               # 최적화기\n",
    "    logging_steps=10,                        # 로그 기록 주기\n",
    "    save_strategy=\"steps\",                   # 저장 전략\n",
    "    save_steps=50,                           # 저장 주기\n",
    "    bf16=True,                              # bfloat16 사용\n",
    "    learning_rate=1e-4,                     # 학습률\n",
    "    max_grad_norm=0.3,                      # 그래디언트 클리핑\n",
    "    warmup_ratio=0.03,                      # 워밍업 비율\n",
    "    lr_scheduler_type=\"constant\",           # 고정 학습률\n",
    "    push_to_hub=False,                      # 허브 업로드 안 함\n",
    "    remove_unused_columns=False,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "    report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b05ef38-fd56-4def-8569-9512bf56b81f",
   "metadata": {},
   "source": [
    "## 4. 학습 중 전처리 함수: collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0c36ca-5d28-4bdf-b27f-ca7ab63b4534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    new_batch = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    for example in batch:\n",
    "        messages = example[\"messages\"]\n",
    "\n",
    "        # LLaMA 3 채팅 템플릿 적용 (시작 토큰 포함)\n",
    "        prompt = \"<|begin_of_text|>\"\n",
    "        for msg in messages:\n",
    "            role = msg[\"role\"]\n",
    "            content = msg[\"content\"].strip()\n",
    "            prompt += f\"<|start_header_id|>{role}<|end_header_id|>\\n{content}<|eot_id|>\"\n",
    "\n",
    "        # 마지막 assistant 메시지는 응답으로 간주하고 레이블에 포함\n",
    "        text = prompt.strip()\n",
    "\n",
    "        # 토큰화\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_seq_length,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        labels = [-100] * len(input_ids)\n",
    "\n",
    "        # assistant 응답의 시작 위치 찾기\n",
    "        assistant_header = \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        assistant_tokens = tokenizer.encode(assistant_header, add_special_tokens=False)\n",
    "        eot_token = \"<|eot_id|>\"\n",
    "        eot_tokens = tokenizer.encode(eot_token, add_special_tokens=False)\n",
    "\n",
    "        # 레이블 범위 지정\n",
    "        i = 0\n",
    "        while i <= len(input_ids) - len(assistant_tokens):\n",
    "            if input_ids[i:i + len(assistant_tokens)] == assistant_tokens:\n",
    "                start = i + len(assistant_tokens)\n",
    "                end = start\n",
    "                while end <= len(input_ids) - len(eot_tokens):\n",
    "                    if input_ids[end:end + len(eot_tokens)] == eot_tokens:\n",
    "                        break\n",
    "                    end += 1\n",
    "                for j in range(start, end):\n",
    "                    labels[j] = input_ids[j]\n",
    "                for j in range(end, end + len(eot_tokens)):\n",
    "                    labels[j] = input_ids[j]  # <|eot_id|> 토큰도 포함\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        new_batch[\"input_ids\"].append(input_ids)\n",
    "        new_batch[\"attention_mask\"].append(attention_mask)\n",
    "        new_batch[\"labels\"].append(labels)\n",
    "\n",
    "    # 패딩 처리\n",
    "    max_length = max(len(ids) for ids in new_batch[\"input_ids\"])\n",
    "    for i in range(len(new_batch[\"input_ids\"])):\n",
    "        pad_len = max_length - len(new_batch[\"input_ids\"][i])\n",
    "        new_batch[\"input_ids\"][i].extend([tokenizer.pad_token_id] * pad_len)\n",
    "        new_batch[\"attention_mask\"][i].extend([0] * pad_len)\n",
    "        new_batch[\"labels\"][i].extend([-100] * pad_len)\n",
    "\n",
    "    for k in new_batch:\n",
    "        new_batch[k] = torch.tensor(new_batch[k])\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094bc1d-d47e-4932-98ba-9d2f30949809",
   "metadata": {},
   "source": [
    "```python\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "시스템 프롬프트<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "유저 프롬프트<|eot_id|><|start_header_id|>assistant<|end_header|>LLM의 답변<|eot_id|>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d5cc839-5f65-44c8-b475-ac613fde97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "처리된 배치 데이터:\n",
      "입력 ID 형태: torch.Size([1, 1107])\n",
      "어텐션 마스크 형태: torch.Size([1, 1107])\n",
      "레이블 형태: torch.Size([1, 1107])\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 최대 길이 제한\n",
    "max_seq_length=8192\n",
    "\n",
    "# collate_fn 테스트 (배치 크기 1. 즉, 데이터 1개에 대해서 전처리를 진행해본다.)\n",
    "example = train_dataset[0]\n",
    "batch = collate_fn([example])\n",
    "\n",
    "print(\"\\n처리된 배치 데이터:\")\n",
    "print(\"입력 ID 형태:\", batch[\"input_ids\"].shape)\n",
    "print(\"어텐션 마스크 형태:\", batch[\"attention_mask\"].shape)\n",
    "print(\"레이블 형태:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7578d30e-fb04-4c6e-974d-a613e7cfa785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 대한 정수 인코딩 결과:\n",
      "[128000, 128006, 9125, 128007, 198, 65895, 83628, 34804, 107849, 104366, 120974, 18359, 107472, 102783, 245, 103850, 229, 55348, 18918, 53017, 44005, 55348, 116425, 20565, 80052, 382, 65895, 83628, 21028, 103135, 48936, 34804, 116100, 103405, 109521, 121002, 18359, 125201, 44005, 123263, 1473, 16, 13, 56773, 125441, 330, 101661, 104366, 107032, 32179, 7, 101661, 104366, 30381, 21028, 56154, 66965, 10143, 18918, 126470, 43139, 11, 116534, 13094, 124110, 25941, 107496, 58901, 109760, 48936, 107849, 24486, 54535, 115096, 53017, 92245, 627, 17, 13, 56773, 125441, 330, 101661, 104366, 107032, 32179, 1, 21028, 330, 56154, 66965, 77437, 107745, 103618, 1, 18918, 82818, 120378, 43139, 11, 116534, 102244, 108280, 104834, 101360, 127923, 102893, 114942, 44005, 111964, 18359, 114839, 92245, 382, 45464, 58, 16, 60, 109760, 54535, 41953, 53017, 111850, 117035, 512, 12, 101264, 105292, 16969, 124110, 25941, 107496, 35495, 84656, 57002, 103684, 109760, 106612, 87472, 17835, 114839, 48936, 72208, 198, 12, 54535, 124788, 49011, 100, 35495, 105131, 89881, 102893, 11, 62060, 112469, 103684, 29833, 102611, 43139, 114839, 48936, 72208, 198, 12, 121686, 105718, 125530, 18359, 120952, 48936, 72208, 25, 330, 167, 99834, 103415, 36811, 32111, 330, 167, 115468, 122665, 32111, 330, 102546, 80732, 34983, 56773, 51402, 10246, 12, 107032, 32179, 73653, 74618, 55055, 88525, 101264, 35495, 11, 64857, 30446, 30426, 54535, 41953, 106612, 87472, 17835, 108098, 72208, 198, 12, 102745, 18359, 67890, 116076, 44005, 50152, 102772, 330, 110399, 89359, 115372, 36811, 32111, 330, 110399, 89359, 18918, 101264, 44005, 103521, 122665, 7673, 107335, 109760, 48936, 72208, 198, 12, 64857, 30446, 30426, 109760, 54535, 41953, 73653, 62226, 101360, 11, 105642, 114942, 106593, 103603, 54535, 89359, 16969, 62226, 88525, 101264, 72208, 271, 103415, 30426, 512, 12, 43449, 25, 220, 16, 32428, 65895, 480, 15259, 11651, 62226, 25, 220, 16, 32428, 65895, 480, 15259, 20565, 5251, 115468, 122665, 5380, 12, 43449, 25, 220, 16, 102757, 104193, 123061, 105292, 26799, 101096, 26799, 11651, 62226, 25, 220, 16, 102757, 104193, 123061, 105292, 26799, 101096, 112953, 123621, 18918, 101264, 44005, 103521, 122665, 1980, 45464, 58, 17, 60, 37155, 21028, 114942, 101824, 102722, 102657, 82158, 111850, 117035, 512, 12, 103405, 122042, 121002, 21028, 99901, 16969, 64857, 30446, 30426, 56069, 13094, 168, 235, 105, 21028, 11240, 106612, 77437, 43139, 62226, 110513, 109670, 627, 12, 110670, 122165, 36092, 112, 102260, 446, 8, 96270, 19954, 120461, 122165, 36092, 112, 102260, 493, 8, 61415, 105642, 103386, 36092, 112, 102260, 18918, 121942, 22035, 96677, 51402, 13, 4823, 56069, 113890, 74177, 99029, 20565, 113610, 61938, 627, 12, 95713, 107744, 88708, 13094, 47782, 18359, 50152, 102772, 330, 123467, 1, 113781, 125530, 62060, 83628, 11, 122292, 81021, 55055, 40147, 108520, 122292, 84734, 10779, 8, 18918, 41820, 110513, 109670, 382, 36811, 89359, 66610, 101868, 512, 12, 77597, 109, 67598, 109, 16582, 109745, 55216, 101015, 103684, 54535, 124788, 104064, 101360, 11, 124110, 25941, 107496, 35495, 24839, 102, 77437, 65621, 114942, 18359, 114839, 92245, 627, 12, 123851, 94772, 37155, 21028, 16969, 220, 17, 93, 18, 52688, 41953, 43139, 115382, 32179, 114942, 34983, 56773, 51402, 13, 103123, 11, 72043, 98934, 53400, 125530, 34804, 107455, 20565, 51402, 627, 12, 37155, 21028, 114942, 99901, 16969, 330, 101661, 104366, 27797, 32179, 30381, 21028, 1, 107739, 108652, 19954, 110038, 54059, 90759, 109670, 382, 71023, 102657, 106434, 111850, 117035, 512, 12, 102722, 102657, 20565, 47782, 18359, 50152, 512, 220, 5324, 101661, 104366, 27797, 32179, 30381, 21028, 794, 39813, 498, 330, 71023, 102657, 101314, 100981, 794, 905, 633, 12, 102722, 102657, 20565, 109077, 50152, 512, 220, 5324, 101661, 104366, 27797, 32179, 30381, 21028, 794, 39813, 498, 330, 71023, 102657, 101314, 100981, 794, 837, 11, 330, 71023, 102657, 794, 510, 101930, 102722, 102657, 81021, 55055, 57575, 62060, 117484, 226, 48424, 2625, 8, 107758, 102704, 104670, 51440, 121751, 107849, 104366, 80732, 84734, 60, 633, 103415, 30426, 43449, 101824, 62226, 512, 12, 43449, 25, 5473, 43, 82, 1305, 76, 1898, 1232, 5473, 101661, 104366, 27797, 32179, 33177, 103304, 73148, 1232, 2570, 20068, 23193, 16, 518, 364, 14052, 931, 20, 4181, 364, 101661, 104366, 27797, 32179, 80732, 62, 24486, 84391, 1232, 2570, 19, 100848, 67945, 104152, 100981, 518, 364, 19, 100848, 67945, 104152, 100981, 4181, 364, 101661, 104366, 27797, 32179, 80732, 62, 24486, 26799, 1232, 2570, 19, 100848, 67945, 104152, 100981, 518, 364, 19, 100848, 67945, 104152, 100981, 4181, 364, 101661, 104366, 27797, 32179, 168, 78147, 1232, 2570, 10731, 16496, 518, 364, 10731, 16496, 4181, 364, 101661, 104366, 27797, 32179, 168, 78147, 80732, 1232, 2570, 101661, 104366, 30381, 21028, 56154, 66965, 518, 364, 101661, 104366, 30381, 21028, 56154, 66965, 4181, 364, 71023, 102657, 1232, 2570, 21121, 57002, 102039, 105519, 55421, 66406, 108168, 107067, 100981, 101824, 49011, 243, 101015, 105633, 30381, 58, 21121, 57002, 102039, 112106, 104366, 63171, 5037, 22, 48424, 11, 220, 2366, 19, 13, 20, 13, 16, 2637, 116686, 60861, 30381, 28938, 364, 127812, 64189, 57519, 33177, 104152, 100981, 101106, 27796, 101999, 67945, 104152, 100981, 19954, 115825, 111850, 30381, 58, 127812, 64189, 112106, 104366, 63171, 8011, 19, 48424, 11, 220, 679, 20, 13, 17, 13, 1544, 2637, 63171, 30381, 60, 4181, 364, 101661, 104366, 27797, 32179, 30381, 21028, 1232, 2570, 55430, 63375, 104152, 100981, 11, 108332, 63375, 104152, 100981, 11, 114602, 100981, 101824, 75086, 43144, 18359, 125274, 24486, 106248, 27796, 19954, 106725, 125744, 44005, 107387, 101264, 52976, 16045, 364, 100848, 67945, 104152, 100981, 108181, 56773, 63375, 104152, 100981, 11, 108332, 63375, 104152, 100981, 11, 114602, 100981, 101824, 75086, 43144, 18359, 125274, 24486, 106248, 27796, 19954, 106725, 220, 220, 19, 33177, 108520, 220, 23, 33177, 18359, 56773, 122211, 55000, 58126, 125744, 44005, 107387, 101264, 52976, 99858, 11498, 12, 62226, 25, 720, 5018, 101661, 104366, 27797, 32179, 30381, 21028, 794, 330, 55430, 63375, 104152, 100981, 11, 108332, 63375, 104152, 100981, 11, 114602, 100981, 101824, 75086, 43144, 18359, 125274, 24486, 106248, 27796, 19954, 106725, 125744, 44005, 107387, 101264, 61938, 10246, 1, 71023, 102657, 101314, 100981, 794, 837, 345, 1, 71023, 102657, 794, 4482, 21121, 57002, 102039, 105519, 55421, 66406, 108168, 107067, 100981, 101824, 49011, 243, 101015, 105633, 30381, 498, 330, 127812, 64189, 57519, 33177, 104152, 100981, 101106, 27796, 101999, 67945, 104152, 100981, 19954, 115825, 111850, 30381, 93546, 128009, 128006, 882, 128007, 198, 543, 354, 479, 13094, 113792, 103415, 36811, 30, 128009, 128006, 78191, 128007, 198, 13922, 101661, 104366, 27797, 32179, 30381, 21028, 1232, 364, 543, 354, 479, 34804, 74769, 65895, 11, 86503, 102997, 106446, 11, 101968, 102997, 11, 101968, 102997, 106446, 11, 101968, 103588, 11, 96102, 65895, 18359, 117460, 61938, 13, 116786, 11, 112700, 65677, 55421, 106593, 75086, 27797, 18359, 110714, 115155, 43139, 74618, 110399, 32179, 96102, 65895, 44005, 107387, 101264, 61938, 13, 96717, 18918, 105510, 11, 99105, 115296, 23955, 108964, 18359, 56773, 55430, 114026, 74769, 65895, 44005, 50152, 61415, 11, 108360, 125189, 75086, 27797, 18359, 110714, 86503, 27796, 19954, 101968, 102997, 44005, 116492, 57575, 41820, 113191, 29833, 103924, 16045, 364, 71023, 102657, 1232, 2290, 11, 364, 71023, 102657, 101314, 100981, 1232, 3641, 92, 128009]\n"
     ]
    }
   ],
   "source": [
    "print('입력에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"input_ids\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b8d7425-6d62-44af-b726-689ca29c6d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input_ids 디코딩 결과:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "당신은 법령 상담을 위한 챗봇 데이터를 생성하는 데이터 전문가입니다.\n",
      "\n",
      "당신의 역할은 아래 두 가지 작업을 수행하는 것입니다:\n",
      "\n",
      "1. 주어진 \"법령 용어(법령정의사전)\"를 기반으로, 고객이 자연스럽게 질문할 법한 문장을 생성하세요.\n",
      "2. 주어진 \"법령 용어\"의 \"사전식 풀이\"를 바탕으로, 고객에게 친절하고 정확하게 설명하는 답변을 작성하세요.\n",
      "\n",
      "---\n",
      "\n",
      "[1] 질문 문장 생성 규칙:\n",
      "- 말투는 자연스럽고 일상적인 질문 형태로 작성할 것\n",
      "- 문장은 짧고 간결하게, 대략적인 수준으로 작성할 것\n",
      "- 다음과 같은 표현을 활용할 것: \"뭐예요?\", \"뭔가요?\", \"설명해 주세요.\"\n",
      "- 용어만 나열하지 말고, 반드시 문장 형태로 만들 것\n",
      "- 사람을 지칭하는 경우에는 \"누구인가요?\", \"누구를 말하는 건가요?\"처럼 질문할 것\n",
      "- 반드시 질문 문장만 출력하고, 다른 설명이나 안내 문구는 출력하지 말 것\n",
      "\n",
      "예시:\n",
      "- 입력: 1인당 GNI → 출력: 1인당 GNI가 뭔가요?\n",
      "- 입력: 1종 금융투자업자 → 출력: 1종 금융투자업자는 누구를 말하는 건가요?\n",
      "\n",
      "---\n",
      "\n",
      "[2] 정의 설명 및 출처 처리 규칙:\n",
      "- 두 번째 작업의 결과는 반드시 파이썬의 dictionary 형식으로 출력해야 합니다.\n",
      "- 큰따옴표(\") 안에 작은따옴표(')나 다른 따옴표를 넣지 마세요. JSON 파싱 오류가 발생합니다.\n",
      "- 해당 항목이 없을 경우에는 \"없음\"이라는 표현 대신, 빈 문자열(\"\") 또는 빈 리스트([])를 사용해야 합니다.\n",
      "\n",
      "요구 조건:\n",
      "- 딱딱하거나 기계적인 문장은 피하고, 자연스럽고 격식 있는 설명을 작성하세요.\n",
      "- 어려운 정의는 2~3문장으로 풀어 설명해 주세요. 단, 중복된 표현은 삼가세요.\n",
      "- 정의 설명 결과는 \"법령용어정의\"라는 키에 담아야 합니다.\n",
      "\n",
      "출처 관련 규칙:\n",
      "- 출처가 없을 경우:\n",
      "  {\"법령용어정의\": \"...\", \"출처유무\": false}\n",
      "\n",
      "- 출처가 있을 경우:\n",
      "  {\"법령용어정의\": \"...\", \"출처유무\": true, \"출처\": [각 출처 문자열에서 대괄호([) 앞까지 잘라낸 법령명 리스트]}\n",
      "\n",
      "예시 입력 및 출력:\n",
      "- 입력: {'LsTrmService': {'법령용어일련번호': ['5077141', '2430005'], '법령용어명_한글': ['4교대근무', '4교대근무'], '법령용어명_한자': ['4교대근무', '4교대근무'], '법령용어코드': ['011402', '011402'], '법령용어코드명': ['법령정의사전', '법령정의사전'], '출처': ['기상청 청원경찰 복무 및 징계규정[기상청훈령 제1117호, 2024.5.1., 일부개정]', '환경부 전일근무관서 교대근무에 관한 규정[환경부훈령 제1144호, 2015.2.27., 제정]'], '법령용어정의': ['주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말한다.', '교대근무자가 주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라  4일 또는 8일을 주기로 하여 실시하는 것을 말한다.']}}\n",
      "- 출력: \n",
      "{\"법령용어정의\": \"주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말합니다.\"\n",
      "\"출처유무\": true,\n",
      "\"출처\": [\"기상청 청원경찰 복무 및 징계규정\", \"환경부 전일근무관서 교대근무에 관한 규정\"]}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "allotment이 뭐예요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "{'법령용어정의': 'allotment은 배당, 부담액, 분담, 분담액, 분배, 할당을 의미합니다. 즉, 어떤 자원이나 비용을 여러 부분으로 나누어 할당하는 것을 말합니다. 예를 들어, 회사의 이익을 주주들에게 배당하는 경우나, 프로젝트 비용을 여러 부서에 분담하는 상황에서 사용될 수 있습니다.', '출처': None, '출처유무': False}<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# 디코딩된 input_ids 출력\n",
    "decoded_text = tokenizer.decode(\n",
    "    batch[\"input_ids\"][0].tolist(),\n",
    "    skip_special_tokens=False,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(\"\\ninput_ids 디코딩 결과:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5ec99e0-5360-40b2-b622-b8c7d2110454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블에 대한 정수 인코딩 결과:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 13922, 101661, 104366, 27797, 32179, 30381, 21028, 1232, 364, 543, 354, 479, 34804, 74769, 65895, 11, 86503, 102997, 106446, 11, 101968, 102997, 11, 101968, 102997, 106446, 11, 101968, 103588, 11, 96102, 65895, 18359, 117460, 61938, 13, 116786, 11, 112700, 65677, 55421, 106593, 75086, 27797, 18359, 110714, 115155, 43139, 74618, 110399, 32179, 96102, 65895, 44005, 107387, 101264, 61938, 13, 96717, 18918, 105510, 11, 99105, 115296, 23955, 108964, 18359, 56773, 55430, 114026, 74769, 65895, 44005, 50152, 61415, 11, 108360, 125189, 75086, 27797, 18359, 110714, 86503, 27796, 19954, 101968, 102997, 44005, 116492, 57575, 41820, 113191, 29833, 103924, 16045, 364, 71023, 102657, 1232, 2290, 11, 364, 71023, 102657, 101314, 100981, 1232, 3641, 92, 128009]\n"
     ]
    }
   ],
   "source": [
    "print('레이블에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"labels\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6938e31-3109-42b9-ae14-8895c087649f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "labels 디코딩 결과 (-100 제외):\n",
      "{'법령용어정의': 'allotment은 배당, 부담액, 분담, 분담액, 분배, 할당을 의미합니다. 즉, 어떤 자원이나 비용을 여러 부분으로 나누어 할당하는 것을 말합니다. 예를 들어, 회사의 이익을 주주들에게 배당하는 경우나, 프로젝트 비용을 여러 부서에 분담하는 상황에서 사용될 수 있습니다.', '출처': None, '출처유무': False}<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# -100이 아닌 부분만 골라 디코딩\n",
    "label_ids = [token_id for token_id in batch[\"labels\"][0].tolist() if token_id != -100]\n",
    "\n",
    "decoded_labels = tokenizer.decode(\n",
    "    label_ids,\n",
    "    skip_special_tokens=False,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(\"\\nlabels 디코딩 결과 (-100 제외):\")\n",
    "print(decoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e849a2-066c-4453-8c85-f997cdaa3e26",
   "metadata": {},
   "source": [
    "## 5. 어텐션 마스크 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c70f56b-7eac-4e3d-8635-c363539bfccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 데이터 길이: 1107\n",
      "1번 데이터 길이: 1091\n",
      "\n",
      "배치 처리 후:\n",
      "입력 ID 형태: torch.Size([2, 1107])\n",
      "어텐션 마스크 형태: torch.Size([2, 1107])\n",
      "0번 샘플 어텐션 마스크 합계: 1107\n",
      "1번 샘플 어텐션 마스크 합계: 1091\n",
      "\n",
      "0번과 1번 샘플의 어텐션 마스크가 다른가요? True\n",
      "\n",
      "0번 샘플 어텐션 마스크: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1번 샘플 어텐션 마스크: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "배치 내 최대 길이: 1107\n",
      "0번 샘플 어텐션 마스크 합계 (실제 토큰 수): 1107\n",
      "1번 샘플 어텐션 마스크 합계 (실제 토큰 수): 1091\n",
      "0번 샘플 어텐션 마스크 1의 개수: 1107\n",
      "0번 샘플 어텐션 마스크 0의 개수: 0\n",
      "1번 샘플 어텐션 마스크 1의 개수: 1091\n",
      "1번 샘플 어텐션 마스크 0의 개수: 16\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 최대 길이 제한\n",
    "max_seq_length = 8192\n",
    "# 0번과 1번 데이터의 길이 확인\n",
    "example0 = train_dataset[0]\n",
    "example1 = train_dataset[1]\n",
    "# 개별 길이 확인 (토큰화 후)\n",
    "tokenized0 = tokenizer(\n",
    "    # 전체 처리 과정과 동일하게 전체 대화를 토큰화\n",
    "    \"<|begin_of_text|>\" + \"\".join([f\"<|start_header_id|>{msg['role']}<|end_header_id|>\\n{msg['content'].strip()}<|eot_id|>\" for msg in example0[\"messages\"]]),\n",
    "    truncation=True,\n",
    "    max_length=max_seq_length,\n",
    "    padding=False,\n",
    "    return_tensors=None,\n",
    ")\n",
    "tokenized1 = tokenizer(\n",
    "    # 전체 처리 과정과 동일하게 전체 대화를 토큰화\n",
    "    \"<|begin_of_text|>\" + \"\".join([f\"<|start_header_id|>{msg['role']}<|end_header_id|>\\n{msg['content'].strip()}<|eot_id|>\" for msg in example1[\"messages\"]]),\n",
    "    truncation=True,\n",
    "    max_length=max_seq_length,\n",
    "    padding=False,\n",
    "    return_tensors=None,\n",
    ")\n",
    "print(f\"0번 데이터 길이: {len(tokenized0['input_ids'])}\")\n",
    "print(f\"1번 데이터 길이: {len(tokenized1['input_ids'])}\")\n",
    "# 배치로 처리하여 어텐션 마스크 비교\n",
    "batch = collate_fn([example0, example1])\n",
    "print(\"\\n배치 처리 후:\")\n",
    "print(f\"입력 ID 형태: {batch['input_ids'].shape}\")\n",
    "print(f\"어텐션 마스크 형태: {batch['attention_mask'].shape}\")\n",
    "# 각 샘플의 어텐션 마스크 합계 (실제 토큰 수 확인)\n",
    "print(f\"0번 샘플 어텐션 마스크 합계: {batch['attention_mask'][0].sum().item()}\")\n",
    "print(f\"1번 샘플 어텐션 마스크 합계: {batch['attention_mask'][1].sum().item()}\")\n",
    "# 0번 샘플과 1번 샘플의 어텐션 마스크가 다른지 확인\n",
    "masks_different = not torch.equal(batch['attention_mask'][0], batch['attention_mask'][1])\n",
    "print(f\"\\n0번과 1번 샘플의 어텐션 마스크가 다른가요? {masks_different}\")\n",
    "# 어텐션 마스크 패턴 시각화 (처음 20개와 마지막 20개 토큰)\n",
    "print(\"\\n0번 샘플 어텐션 마스크:\", batch['attention_mask'][0].tolist())\n",
    "print(\"1번 샘플 어텐션 마스크:\", batch['attention_mask'][1].tolist())\n",
    "# 배치 내에서 가장 긴 시퀀스 길이 구하기\n",
    "max_length_in_batch = max(len(tokenized0['input_ids']), len(tokenized1['input_ids']))\n",
    "print(f\"\\n배치 내 최대 길이: {max_length_in_batch}\")\n",
    "print(f\"0번 샘플 어텐션 마스크 합계 (실제 토큰 수): {batch['attention_mask'][0].sum().item()}\")\n",
    "print(f\"1번 샘플 어텐션 마스크 합계 (실제 토큰 수): {batch['attention_mask'][1].sum().item()}\")\n",
    "print(f\"0번 샘플 어텐션 마스크 1의 개수: {batch['attention_mask'][0].sum().item()}\")\n",
    "print(f\"0번 샘플 어텐션 마스크 0의 개수: {(batch['attention_mask'][0] == 0).sum().item()}\")\n",
    "print(f\"1번 샘플 어텐션 마스크 1의 개수: {batch['attention_mask'][1].sum().item()}\")\n",
    "print(f\"1번 샘플 어텐션 마스크 0의 개수: {(batch['attention_mask'][1] == 0).sum().item()}\")\n",
    "# 결과 검증: 긴 샘플은 모든 어텐션 마스크가 1이고, 짧은 샘플은 일부만 1이어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b02034c-61ba-4fe6-84dd-408fd27d6fed",
   "metadata": {},
   "source": [
    "## 6. 전처리 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc5ff1-ea33-4ef2-a1dc-a6efd97cbbe4",
   "metadata": {},
   "source": [
    "## 7. 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe99cff0-d149-4ed5-8e8d-b62642165aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이 설정\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44eff24a-0f63-4d91-9c89-c15410fce0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 14:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.364000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.909800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.838800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.805800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.832800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.718800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.700200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.721600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.807800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.790300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.807600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.682700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.732900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.613300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.685400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.729400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.618200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.700600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.554900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.602300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.598000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.711100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.583300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.619900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.670200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.566200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.619900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.542500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.550700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.543300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.527900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.516400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.588500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.561700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.542600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.564900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.573800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.507400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "trainer.train()   # 모델이 자동으로 허브와 output_dir에 저장됨\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model()   # 최종 모델을 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a78dac-8258-41f6-9e1a-b049ca8f0ba9",
   "metadata": {},
   "source": [
    "## 8. 테스트 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e8254-77c8-4a54-9132-131c432e9505",
   "metadata": {},
   "source": [
    "실제 모델에 입력을 넣을 때에는 입력의 뒤에 `<|start_header_id|>assistant<|end_header_id|>\\n`가 부착되어서 넣는 것이 좋습니다. 그러면 모델이 조금 더 안정적으로 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4e1e2b4-7181-416a-8014-1018144ce6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lst = []\n",
    "label_lst = []\n",
    "\n",
    "for messages in test_dataset[\"messages\"]:\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    input = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[0] + '<|start_header_id|>assistant<|end_header_id|>\\n'\n",
    "    label = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[1].split('<|eot_id|>')[0]\n",
    "    prompt_lst.append(input)\n",
    "    label_lst.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f56d478b-4e31-4369-9ba1-b3861a8cc0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 법령 상담을 위한 챗봇 데이터를 생성하는 데이터 전문가입니다.\n",
      "\n",
      "당신의 역할은 아래 두 가지 작업을 수행하는 것입니다:\n",
      "\n",
      "1. 주어진 \"법령 용어(법령정의사전)\"를 기반으로, 고객이 자연스럽게 질문할 법한 문장을 생성하세요.\n",
      "2. 주어진 \"법령 용어\"의 \"사전식 풀이\"를 바탕으로, 고객에게 친절하고 정확하게 설명하는 답변을 작성하세요.\n",
      "\n",
      "---\n",
      "\n",
      "[1] 질문 문장 생성 규칙:\n",
      "- 말투는 자연스럽고 일상적인 질문 형태로 작성할 것\n",
      "- 문장은 짧고 간결하게, 대략적인 수준으로 작성할 것\n",
      "- 다음과 같은 표현을 활용할 것: \"뭐예요?\", \"뭔가요?\", \"설명해 주세요.\"\n",
      "- 용어만 나열하지 말고, 반드시 문장 형태로 만들 것\n",
      "- 사람을 지칭하는 경우에는 \"누구인가요?\", \"누구를 말하는 건가요?\"처럼 질문할 것\n",
      "- 반드시 질문 문장만 출력하고, 다른 설명이나 안내 문구는 출력하지 말 것\n",
      "\n",
      "예시:\n",
      "- 입력: 1인당 GNI → 출력: 1인당 GNI가 뭔가요?\n",
      "- 입력: 1종 금융투자업자 → 출력: 1종 금융투자업자는 누구를 말하는 건가요?\n",
      "\n",
      "---\n",
      "\n",
      "[2] 정의 설명 및 출처 처리 규칙:\n",
      "- 두 번째 작업의 결과는 반드시 파이썬의 dictionary 형식으로 출력해야 합니다.\n",
      "- 큰따옴표(\") 안에 작은따옴표(')나 다른 따옴표를 넣지 마세요. JSON 파싱 오류가 발생합니다.\n",
      "- 해당 항목이 없을 경우에는 \"없음\"이라는 표현 대신, 빈 문자열(\"\") 또는 빈 리스트([])를 사용해야 합니다.\n",
      "\n",
      "요구 조건:\n",
      "- 딱딱하거나 기계적인 문장은 피하고, 자연스럽고 격식 있는 설명을 작성하세요.\n",
      "- 어려운 정의는 2~3문장으로 풀어 설명해 주세요. 단, 중복된 표현은 삼가세요.\n",
      "- 정의 설명 결과는 \"법령용어정의\"라는 키에 담아야 합니다.\n",
      "\n",
      "출처 관련 규칙:\n",
      "- 출처가 없을 경우:\n",
      "  {\"법령용어정의\": \"...\", \"출처유무\": false}\n",
      "\n",
      "- 출처가 있을 경우:\n",
      "  {\"법령용어정의\": \"...\", \"출처유무\": true, \"출처\": [각 출처 문자열에서 대괄호([) 앞까지 잘라낸 법령명 리스트]}\n",
      "\n",
      "예시 입력 및 출력:\n",
      "- 입력: {'LsTrmService': {'법령용어일련번호': ['5077141', '2430005'], '법령용어명_한글': ['4교대근무', '4교대근무'], '법령용어명_한자': ['4교대근무', '4교대근무'], '법령용어코드': ['011402', '011402'], '법령용어코드명': ['법령정의사전', '법령정의사전'], '출처': ['기상청 청원경찰 복무 및 징계규정[기상청훈령 제1117호, 2024.5.1., 일부개정]', '환경부 전일근무관서 교대근무에 관한 규정[환경부훈령 제1144호, 2015.2.27., 제정]'], '법령용어정의': ['주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말한다.', '교대근무자가 주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라  4일 또는 8일을 주기로 하여 실시하는 것을 말한다.']}}\n",
      "- 출력: \n",
      "{\"법령용어정의\": \"주간근무, 야간근무, 휴무 및 비번을 일정한 순서에 따라 실시하는 것을 말합니다.\"\n",
      "\"출처유무\": true,\n",
      "\"출처\": [\"기상청 청원경찰 복무 및 징계규정\", \"환경부 전일근무관서 교대근무에 관한 규정\"]}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "abidance가 뭐예요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_lst[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "157493fd-bab0-4d18-a2d0-e85eab42e7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'법령용어정의': \"abidance는 '준수'라는 의미를 가지고 있습니다. 이는 법이나 규칙을 따르는 것을 의미합니다. 예를 들어, 교통법규를 준수한다는 것은 교통 신호를 지키고 제한 속도를 준수하는 것을 포함합니다.\", '출처': None, '출처유무': False}\n"
     ]
    }
   ],
   "source": [
    "print(label_lst[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a825b-89c3-4288-9c97-2c3c7f01ad16",
   "metadata": {},
   "source": [
    "## 9. 파인튜닝 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "043328ae-7ad0-41c3-b6c6-aedab0b8ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import  AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dac6d4d-2012-4603-9a62-da33a253e29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4c03d9dc1447a58d5765891c0a3e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "peft_model_id = \"llama3-8b-qa-ko/checkpoint-600\"\n",
    "fine_tuned_model = AutoPeftModelForCausalLM.from_pretrained(peft_model_id, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "pipe = pipeline(\"text-generation\", model=fine_tuned_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1190ab71-0f39-44c3-9f89-55c0ab4b23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = tokenizer(\"<|eot_id|>\",add_special_tokens=False)[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e846a9-3b68-4ba3-846e-e8f54b4667c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(pipe, prompt):\n",
    "    outputs = pipe(prompt, max_new_tokens=1024, eos_token_id=eos_token, do_sample=False)\n",
    "    return outputs[0]['generated_text'][len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cd6da67-6672-4dc4-af0e-88052b7144ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    response:\n",
      "{'법령용어정의': '119감염관리실은 감염병의 발생, 확산, 예방, 대응을 위한 감염관리 및 정보관리 업무를 수행하는 기관을 의미합니다. 쉽게 말해, 감염병에 대한 정보를 수집하고 관리하여 대응 전략을 세우는 역할을 하는 곳입니다.', '출처': ['질병관리본부 감염병관리규정'], '출처유무': True}\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '119감염관리실은 감염예방 및 관리를 위해 구조ㆍ구급대원들이 장비 재처리, 물품 및 의약품 보관, 의료폐기물 관리 등을 할 수 있도록 설치된 공간을 의미합니다. 쉽게 말해, 구조와 구급 활동 중 발생할 수 있는 감염 위험을 줄이기 위해 마련된 전문적인 관리 공간이라고 생각하시면 됩니다.', '출처': ['119감염관리실 설치·운영에 관한 규정'], '출처유무': True}\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "{'법령용어정의': '119구급대는 응급구급을 제공하는 구급대와 구급차를 의미합니다. 즉, 응급 상황에서 환자를 신속하게 치료하고 병원으로 이송하기 위해 출동하는 팀을 말합니다. 이들은 응급 상황에 대비하여 필요한 의료 장비와 약품을 갖추고 있어야 하며, 환자의 생명을 구하기 위해 최선을 다합니다.', '출처': ['구급대 및 구급차 운영에 관한 규정'], '출처유무': True}\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '119구급대는 구급활동에 필요한 장비를 갖추고 소방공무원으로 구성된 단위조직을 의미합니다. 쉽게 말해, 응급 상황에서 신속하게 대응할 수 있도록 준비된 팀이라고 생각하시면 됩니다.', '출처': ['119구조ㆍ구급에 관한 법률'], '출처유무': True}\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "{'법령용어정의': '119구조견은 구조물의 안전성을 평가하고, 필요한 경우 구조물의 안전을 보장하기 위해 사용되는 전문적인 서비스를 제공하는 사람을 의미합니다. 쉽게 말해, 건물이나 구조물이 안전한지 확인하는 일을 하는 사람이라고 생각하시면 됩니다.', '출처': ['구조물안전관리법'], '출처유무': True}\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '119구조견은 위급한 상황에서 소방활동을 보조하기 위해 소방기관에서 운용하는 개를 말합니다. 이 구조견은 재난구조, 산악구조, 수난탐지, 사체탐지, 화재탐지 등 다양한 상황에서 구조대상자의 위치를 찾는 역할을 합니다. 예를 들어, 재난구조견은 건물 붕괴현장에서 매몰된 사람을 찾고, 산악구조견은 산악지형에서 실종된 사람을 찾는 데 도움을 줍니다.', '출처': ['119구조견 관리운용 규정', '119구조ㆍ구급에 관한 법률'], '출처유무': True}\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "{'법령용어정의': '119구조견교육대는 구조견을 교육하고 훈련시키는 단체를 의미합니다. 구조견은 사람이나 동물을 구조하기 위해 훈련된 강아지로, 응급 상황에서 중요한 역할을 합니다. 이 교육대는 구조견의 전문성을 높이고, 응급 상황에서의 효율적인 활동을 돕기 위해 설립되었습니다.', '출처': ['구조견교육대 운영지침'], '출처유무': True}\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '119구조견교육대는 구조견의 양성, 훈련, 평가, 시ㆍ도 보급 및 관리전환과 구조견 운용자 교육 등 관련 업무를 총괄하는 중앙119구조본부의 단위조직입니다. 이 조직은 구조견의 훈련과 관리, 그리고 구조견 운용자 교육을 담당하며, 다양한 전문가들이 함께 일하고 있습니다. 예를 들어, 훈련관은 구조견과 운용자를 교육하고 출동을 지원하며, 수의사는 구조견의 건강을 관리하고, 사육관리사는 구조견의 사육과 위생을 책임집니다. 또한, 훈련 중인 훈련견, 번식을 위한 종모견, 그리고 일반 분양을 위한 관리견 등 다양한 유형의 개들이 포함되어 있습니다.', '출처': ['119구조견 관리운용 규정'], '출처유무': True}\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "{'법령용어정의': '119구조견대는 응급구조, 응급의료, 응급통신, 응급운수 등 응급구조활동을 지원하는 구조견대를 의미합니다. 쉽게 말해, 응급 상황에서 필요한 다양한 구조 활동을 한 곳에서 모아놓은 팀이라고 생각하시면 됩니다.', '출처': ['구조활동지원법'], '출처유무': True}\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '위급한 상황에서 구조견을 활용하여 소방활동을 수행하는 소방공무원으로 편성된 중앙119구조본부 및 각 시ㆍ도 소방본부의 단위조직을 말합니다. 이 조직은 구조견 운용자와 보조자로 구성되며, 구조견 운용자는 구조견을 활용하여 현장에 출동하고 관리하는 역할을 맡고, 보조자는 구조견 운용자를 지원하며 구조견의 사육 및 안전점검을 담당합니다.', '출처': ['119구조견 관리운용 규정', '119구조ㆍ구급에 관한 법률'], '출처유무': True}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt, label in zip(prompt_lst[10:15], label_lst[10:15]):\n",
    "    # print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(pipe, prompt)}\")\n",
    "    print(f\"    label:\\n{label}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84388175-c0da-432a-b4a0-5333ae1c7feb",
   "metadata": {},
   "source": [
    "## 10. 기본 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49751b0-4dc2-43a7-a771-314e012b65c1",
   "metadata": {},
   "source": [
    "이번에는 LoRA Adapter를 merge하지 않은 기본 모델로 테스트 데이터에 대해서 인퍼런스해보겠습니다.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29c4c78d-50d0-4aeb-911b-989d691a1101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbcdf4b52c24fc3a969b7653de9d670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0adeb550-b6c2-4783-b174-344e695a3641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    response:\n",
      "119감염관리실은 공공보건에 관련된 질병 및 감염병 발생 시 신속하고 효과적인 대응을 위해 설립된 기관입니다.\n",
      "\n",
      "법령용어정의:\n",
      "{\n",
      "  \"119감염관리실\": \"공공보건에 관련된 질병 및 감염병 발생 시 신속하고 효과적인 대응을 위해 설립된 기관입니다.\",\n",
      "  \"출처유무\": true,\n",
      "  \"출처\": [\"질병관리청\"]\n",
      "}\n",
      "\n",
      "설명:\n",
      "119감염관리실은 질병관리청(예전에는 보건복지부)에 속해 있는 기관으로, 주로 전염병이나 감염병 등 공중보건 위협 요소에 대응하기 위해 설립되었습니다. \n",
      "\n",
      "이 기관은 질병 발생 시 즉각적인 조치를 취하고, 관련 정보를 수집, 분석, 전달함으로써 질병 확산을 최소화하고 대중보건을 보호하는 역할을 합니다. \n",
      "\n",
      "119감염관리실의 주요 업무로는 감염병 발생 사례 신고 접수, 환자 추적 및 격리 조치, 의료진 및 시민 교육 등이 포함됩니다. \n",
      "\n",
      "이 기관의 이름에서 알 수 있듯이, '119'는 응급 상황에 대한 신고 전화번호를 상징하며, '감염관리실'은 그들이 주로 다루는 감염병 관리라는 의미를 내포하고 있습니다. \n",
      "\n",
      "119감염관리실은 각 지역마다 존재하며, 현지 질병 발생 시 현장에서 직접 대응하고 중앙 정부와 협력하여 전반적인 대응 방안을 수립합니다.\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '119감염관리실은 감염예방 및 관리를 위해 구조ㆍ구급대원들이 장비 재처리, 물품 및 의약품 보관, 의료폐기물 관리 등을 할 수 있도록 설치된 공간을 의미합니다. 쉽게 말해, 구조와 구급 활동 중 발생할 수 있는 감염 위험을 줄이기 위해 마련된 전문적인 관리 공간이라고 생각하시면 됩니다.', '출처': ['119감염관리실 설치·운영에 관한 규정'], '출처유무': True}\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "119구급대는 응급상황 발생 시 즉각 현장으로 출동하여 환자 치료를 제공하는 전문 의료팀을 말합니다.\n",
      "\n",
      "법령용어정의:\n",
      "{\n",
      "  \"119구급대\": \"응급상황 발생 시 즉각 현장으로 출동하여 환자 치료를 제공하는 전문 의료팀입니다.\",\n",
      "  \"출처유무\": true,\n",
      "  \"출처\": [\"의료법\", \"응급의료법\"]\n",
      "} \n",
      "\n",
      "의료법 제17조에 따르면, \"응급상황 발생 시 즉각 구호 조치가 필요한 사람에게 의료인력과 장비를 동원하여 직접 현장으로 출동하여 치료를 시행하는 업무를 구급대(이하 \"119구급대\"라 한다)라 합니다.\"\n",
      "\n",
      "응급의료법 제2조(목적)에서도 \"응급상황 발생 시 신속하고 효율적인 의료조치를 통해 생명을 구하고 건강을 회복시키는 것\"을 목적으로 하고 있습니다. \n",
      "\n",
      "따라서 119구급대는 응급상황 발생 시 신속한 의료조치를 위해 현장으로 출동하는 전문 의료팀이라는 정의를 내릴 수 있습니다.\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '119구급대는 구급활동에 필요한 장비를 갖추고 소방공무원으로 구성된 단위조직을 의미합니다. 쉽게 말해, 응급 상황에서 신속하게 대응할 수 있도록 준비된 팀이라고 생각하시면 됩니다.', '출처': ['119구조ㆍ구급에 관한 법률'], '출처유무': True}\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "119구조견은 구조활동에 종사하는 개체를 말합니다.\n",
      "\n",
      "법령용어정의:\n",
      "119구조견은 구조활동을 위해 훈련받은 개체로, 사람이나 동물의 구조를 돕거나 위험 상황에서 사람의 생명을 구하기 위해 사용되는 개체를 말합니다.\n",
      "\n",
      "법령용어정의에 대한 출처:\n",
      "- 동물보호법 시행령 제3조의2에 따르면, 구조견은 구조활동을 위한 훈련을 받은 개체로 정의되고 있습니다.\n",
      "- 구조견의 훈련 기준은 농림축산식품부의 '동물보호법 시행령 제3조의2 단서 1'에 명시되어 있습니다.\n",
      "- 또한, '동물보호법 시행령 제3조의2 단서 2'에서는 구조견의 활동 범위를 구체적으로 설명하고 있습니다.\n",
      "\n",
      "{\"법령용어정의\": \"119구조견은 구조활동을 위해 훈련받은 개체로, 사람이나 동물의 구조를 돕거나 위험 상황에서 사람의 생명을 구하기 위해 사용되는 개체를 말합니다.\",\n",
      "\"출처유무\": true,\n",
      "\"출처\": [\"동물보호법 시행령 제3조의2\", \"동물보호법 시행령 제3조의2 단서 1\", \"동물보호법 시행령 제3조의2 단서 2\"]}\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '119구조견은 위급한 상황에서 소방활동을 보조하기 위해 소방기관에서 운용하는 개를 말합니다. 이 구조견은 재난구조, 산악구조, 수난탐지, 사체탐지, 화재탐지 등 다양한 상황에서 구조대상자의 위치를 찾는 역할을 합니다. 예를 들어, 재난구조견은 건물 붕괴현장에서 매몰된 사람을 찾고, 산악구조견은 산악지형에서 실종된 사람을 찾는 데 도움을 줍니다.', '출처': ['119구조견 관리운용 규정', '119구조ㆍ구급에 관한 법률'], '출처유무': True}\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "119구조견교육대는 구조견 훈련을 담당하는 기관이에요.\n",
      "\n",
      "법령용어정의:\n",
      "119구조견교육대는 구조견의 전문적인 훈련을 제공하고 관리하는 교육기관을 말합니다. 이들은 구조견의 기본 훈련, 구조 활동 훈련, 재난 구조 훈련 등을 실시하여 구조견의 능력을 향상시키고, 현장에서의 효율적인 활동을 지원합니다.\n",
      "\n",
      "출처:\n",
      "- 구조견 훈련법 시행령(건강복지부 장관령 제2020-123호)\n",
      "- 구조견 훈련 및 관리에 관한 법률(제정 2021.3.8.)\n",
      "\n",
      "이 정보는 법령 정의 사전에 직접적으로 언급된 내용을 바탕으로 작성되었습니다. 추가적인 정보나 구체적인 내용은 해당 법령이나 관련 규정을 참조하시는 것이 좋겠습니다.\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '119구조견교육대는 구조견의 양성, 훈련, 평가, 시ㆍ도 보급 및 관리전환과 구조견 운용자 교육 등 관련 업무를 총괄하는 중앙119구조본부의 단위조직입니다. 이 조직은 구조견의 훈련과 관리, 그리고 구조견 운용자 교육을 담당하며, 다양한 전문가들이 함께 일하고 있습니다. 예를 들어, 훈련관은 구조견과 운용자를 교육하고 출동을 지원하며, 수의사는 구조견의 건강을 관리하고, 사육관리사는 구조견의 사육과 위생을 책임집니다. 또한, 훈련 중인 훈련견, 번식을 위한 종모견, 그리고 일반 분양을 위한 관리견 등 다양한 유형의 개들이 포함되어 있습니다.', '출처': ['119구조견 관리운용 규정'], '출처유무': True}\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "119구조견대란 119에 신고된 응급상황 현장으로 즉시 출동하여 구조 작업을 수행하는 전문 인력과 장비를 말합니다.\n",
      "\n",
      "법령용어정의:\n",
      "119구조견대는 119에 신고된 응급상황 현장으로 즉시 출동하여 다음과 같은 구조 작업을 수행하는 전문 인력과 장비를 말합니다:\n",
      "1. 인명 구조 및 구급\n",
      "2. 재난 구조 및 대응\n",
      "3. 화재 진압 및 소화\n",
      "4. 교통사고 현장 안전 조치\n",
      "\n",
      "119구조견대는 소방대원, 구급대원, 경찰관 등 다양한 전문가로 구성되어 있으며, 각종 응급 상황에 대응할 수 있는 특수 장비와 차량을 운영합니다.\n",
      "\n",
      "법령용어정의에 대한 출처:\n",
      "- 소방청. (2023). 소방업 종사자 교육 및 자격 규제에 관한 법률 제정 배경과 내용. \n",
      "- 질병관리청. (2022). 응급의학 전문 인력 양성 및 교육 지원 사업 안내.\n",
      "- 경찰청. (2021). 경찰의 임무와 역할. \n",
      "\n",
      "출처유무: true\n",
      "출처:\n",
      "- 소방청\n",
      "- 질병관리청\n",
      "- 경찰청\n",
      "    label:\n",
      "\n",
      "{'법령용어정의': '위급한 상황에서 구조견을 활용하여 소방활동을 수행하는 소방공무원으로 편성된 중앙119구조본부 및 각 시ㆍ도 소방본부의 단위조직을 말합니다. 이 조직은 구조견 운용자와 보조자로 구성되며, 구조견 운용자는 구조견을 활용하여 현장에 출동하고 관리하는 역할을 맡고, 보조자는 구조견 운용자를 지원하며 구조견의 사육 및 안전점검을 담당합니다.', '출처': ['119구조견 관리운용 규정', '119구조ㆍ구급에 관한 법률'], '출처유무': True}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt, label in zip(prompt_lst[10:15], label_lst[10:15]):\n",
    "    # print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(pipe, prompt)}\")\n",
    "    print(f\"    label:\\n{label}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba095f-013b-4bae-b6a1-d0fd25512f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
